<!DOCTYPE html>

<html>
    <head>
        <link type="text/css" rel="stylesheet" href="rCzyrnik.css"/>
        <title> Fraud Detection </title>
    </head>

    <body>

<!--/*><><><><><><><><><><><><>  HEADER  <><><><><><><><><><><*/-->
    <div class="header">

      <a href="index.html">
        <img id="home_button" src="home.png" width="40pt">
      </a>
      <h1> FRAUD DETECTION </h1>
    </div>

<!--/*><><><><><><><><><><><><>  NAVBAR  <><><><><><><><><><><*/-->
    <div class="navbar">
        <table>
            <tr>
                <th><a href="proj_priceprediction.html">Price Prediction</a></th>
                <th><a href="fun_calculators.html">Calculators</a></th>
                <th><a href="fun_camera.html">Camera</a></th>
                <th><a href="fun_doggames.html">Dog Games</a></th>
                <th><a href="fun_spectroscope.html">Spectroscope</a></th>
                <th><a href="fun_shortprojects.html">Short Projects</a></th>
            </tr>
        </table>
    </div>

    <div class="main_content">

      <div style="width:100%; font-size:80%; text-align:center;">
        <img src="caseStudies/fraud_mission.png"
              alt="alternate text"
              width="80%"
              height="80%"
              />
              <br >

      </div>
        <h1> GOAL </h1>

        <p> Identify possible fraud for an online retailer. </p>

        <h1> INTRODUCTION </h1>

        <p> This was the last case study I did for Galvanize. We worked on it
          over the last two days of the course and presented in the afternoon
          right before graduation.
        </p>

        <p> It was amazing to see how far we had come from our first case study
          back in November. We worked a lot more effectively and were able to
          divide tasks up based on our specailties.
        </p>

        <p> My primary role was at the begining of the project, cleaning data,
          doing some exploratory data analysis, and creating the model we used
          to predict fraud.
        </p>

        <h1> THE DATA </h1>

        <p> The training dataset is made of 14,337 events, of which 1288 are
          identified by the company as fraud (8.98%). For each event, there are
          44 columns of information about the event.
        </p>

        <h1> DATA CLEANING </h1>


        <p> Pandas has a great tool for reading Json files, so most of the data
         was unpacked in a single line as
       </p>

        <div><pre><code>
        df = pd.read_json('/data/data.json')
        </code></pre></div>

        <p> There were a couple columns that had nested json, such as "ticket_types".
         A typical event might look like:
       </p>

        <div><pre><code>
          [{'availability': 1,
          'cost': 25.0,
          'event_id': 527017,
          'quantity_sold': 0,
          'quantity_total': 800},
          {'availability': 1,
          'cost': 50.0,
          'event_id': 527017,
          'quantity_sold': 0,
          'quantity_total': 100},
          {'availability': 1,
          'cost': 550.0,
          'event_id': 527017,
          'quantity_sold': 0,
          'quantity_total': 20}]
          </code></pre></div>

        <p> With three ticket types at $25, $50, and $550, with
         800, 100, and 20 available at each level.
        </p>

        <p> To turn this into useful information, I wrote helper functions
          to calculate the total possible profit and the number of tickets for
          each event. I could then use simple division to find the average
          ticket price, and the lenght function gave me the number of ticket types.
        </p>


        <div><pre><code>
          def get_max_profit(row):
              return sum(level['cost']*level['quantity_total'] for level in row)
          def get_num_tickets(row):
              return sum(level['quantity_total'] for level in row)

          df['ticket_types_num_types'] = df.ticket_types.apply(len)
          df['ticket_types_max_profit'] = df.ticket_types.apply(get_max_profit)
          df['ticket_types_num_tickets'] = df.ticket_types.apply(get_num_tickets)
          df['ticket_types_avg_price'] = df.ticket_types_max_profit/df.ticket_types_num_tickets
          </code></pre></div>

          <p> I used a similar method to get information about previous
            payouts, as well as some simple datetime-ing to get information about
            the hour, day, and date the event was created.
          </p>

          <p> The last step in data cleaning was to fill in NaN values with
            the mean from that column. This was only an issue for "has header",
            "average ticket price", and "average payout".
          </p>

          <h1> BUILDING A SIMPLE MODEL </h1>

          <p> Fittling a model was fairly straightforward. I split the data into
            train and test sets using sklearn's model selection "train_test_split".
          </p>

          <p> I also oversampled from the fraud cases because they made such a
            small proportion of the total (less than 10%). By oversampling I
            can create a more balanced dataset.
          </p>

          <p> I ran the data through sklearn's GradientBoostingClassifier (my
            favorite). Even without fine tuning the parameters, I was able to
            get a very impressive 87% recall, 93% precision, and 98% accuracy.
          </p>

          <p> At this point, I handed the cleaned data and model to another team
            member to gridsearch, and I took a look at the most significant
            features.
          </p>


          <h1> INVESTIGATING RESULTS </h1>

          <p> From my simple model, the most important features were:
          </p>

          <ul>
            <li>event_created</li>
            <li>previous_payouts_value_payouts</li>
            <li>previous_payouts_num_payouts</li>
            <li>body_length</li>
            <li>ticket_types_avg_price</li>
          </ul>


          <h2>event_created</h2>




          <br/>
          <br/>
          <br/>
          <br/>




     </div>

  </body>
